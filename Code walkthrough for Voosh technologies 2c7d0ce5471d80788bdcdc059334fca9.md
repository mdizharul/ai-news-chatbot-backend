# Code walkthrough for Voosh technologies

Created Date: December 12, 2025

# ğŸš€ **Overview**

This is an end-to-end **RAG-based News Chatbot** that retrieves the latest world news, embeds articles using **Jina embeddings**, stores vectors inside **Qdrant**, retrieves relevant content using semantic search, and generates summaries or answers using **Google Gemini**.

The app is full-stack:

- **Backend:** Node.js + Express
- **Frontend:** React + Vite
- **Vector DB:** Qdrant
- **Embeddings:** Jina
- **LLM:** Gemini
- **Cache / Sessions:** Redis Cloud

The system fetches news at startup, warms caches, precomputes embeddings, and serves intelligent, source-grounded responses to user queries.

This project is built for interview-ready demonstration: clean architecture, cache layers, batching, LLM prompt engineering, and RAG pipeline.

---

# ğŸŒ **Live Features**

### âœ”ï¸ Fetches 50+ real-time news articles

### âœ”ï¸ Batches embeddings using Jina

### âœ”ï¸ Stores & indexes embeddings in Qdrant

### âœ”ï¸ Performs ANN vector search for relevant articles

### âœ”ï¸ Uses Gemini to generate summarised answers

### âœ”ï¸ Maintains per-session conversation history via Redis

### âœ”ï¸ Auto TTL-based cleanup

### âœ”ï¸ Modern chat UI with source citations

### âœ”ï¸ Fully deployable on Render + Vercel

---

# ğŸ—ï¸ **System Architecture**

Below is a high-level architecture diagram of the entire system:

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚        Frontend         â”‚
                â”‚   (React + Vite)        â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚  REST API Calls
                           â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚       Backend API       â”‚
                â”‚    (Node.js + Express)  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     Initialization         â”‚ Chat Flow
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                                                      â”‚
     â–¼                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RSS Feeds     â”‚                                 â”‚ Redis (Sessions) â”‚
â”‚ Fetch Articles â”‚                                 â”‚ Chat history TTL â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ 50 Articles Loaded                          TTL=3600 seconds
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Jina Embeddings   â”‚
â”‚ Batch = 10         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ Embeddings
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Qdrant Vector Database     â”‚
â”‚  - Cosine similarity search    â”‚
â”‚  - Store vectors + metadata    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ Query Embedding
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       RAG + Prompt Builder      â”‚
â”‚ Retrieve top-k relevant chunks  â”‚
â”‚ Build grounded LLM prompt       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚ Context + Query
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Gemini LLM              â”‚
â”‚   Answer + Summaries + Sources â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

# ğŸ” **End-to-End Flow (Code Walkthrough)**

## **1. Startup: Cache Warming & Embedding Pipeline**

### ğŸ”¹ Step 1 â€” Fetch news articles

On server start, `initializeServices()` runs:

```jsx
newsArticles = await fetchNewsArticles();

```

It loads 50 articles from RSS feeds into memory.

---

### ğŸ”¹ Step 2 â€” Create batched embeddings using Jina

`createArticleEmbeddings()` embeds all articles in **batches of 10**:

```jsx
ğŸ“¦ Processing batch 1/5
ğŸ“Š Calling Jina API...

```

If Jina fails, the code automatically falls back to local simple embeddings.

---

### ğŸ”¹ Step 3 â€” Store embeddings in Qdrant

For each article:

```jsx
{
  id: <articleId>,
  vector: <embedding>,
  payload: { title, link, excerpt }
}

```

Upserted into Qdrant for fast semantic search.

Your backend logs show:

```
Created and stored 50 embeddings in Qdrant

```

---

## **2. Query-Time Flow (When User Sends a Message)**

### ğŸ”¹ Step 1 â€” Frontend sends message

```jsx
POST /api/chat
{
  message: "...",
  sessionId: "..."
}

```

---

### ğŸ”¹ Step 2 â€” Embed user query

Backend calls Jina again for single text:

```
Calling Jina API for 1 text...

```

---

### ğŸ”¹ Step 3 â€” Vector search in Qdrant

Search top-k (20) similar news articles:

```jsx
Found 20 relevant articles
Scores: 0.78, 0.77, 0.75 ...

```

---

### ğŸ”¹ Step 4 â€” RAG Prompt Construction

Selected article snippets + metadata are added to Gemini prompt:

```
Sources:
1. Title...
2. Title...

```

---

### ğŸ”¹ Step 5 â€” Gemini LLM generates final summary

Backend sends final answer including citations:

```json
{
  "response": "...summary...",
  "sources": [...]
}

```

---

## **3. Redis Session Caching + TTL**

### âœ” Stores entire conversation history

Each message is appended to:

```
session:<sessionId>

```

### âœ” TTL = 3600 seconds

```jsx
await redisClient.expire(redisKey, CONFIG.SESSION_TTL);

```

TTL resets on every message â†’ old sessions auto-clean.

This fulfills the assignment requirement for:

- State management
- Cleanup
- Caching layer

---

# ğŸ’» **Frontend Code Flow**

Frontend is built with **React + Vite**.

### âœ” Creates a session once

On load:

```jsx
POST /api/sessions
```

### âœ” Sends messages to backend

On user submit:

```jsx
POST /api/chat
```

### âœ” Displays results

- Assistant message bubble
- Source citations
- Scroll management
- Loading indicator

Beautiful and professional UX.

---

# âš™ï¸ **Installation & Running Locally**

### **Backend**

```bash
cd backend
npm install
npm start
```

Environment variables required:

```
PORT=5000
GEMINI_API_KEY=
GEMINI_MODEL=gemini-1.5-flash-latest
JINA_API_KEY=
REDIS_URL=
VECTOR_DB=qdrant
QDRANT_URL=
QDRANT_API_KEY=
VECTOR_DIM=1536
```

---

### **Frontend**

```bash
cd frontend
npm install
npm run dev
```

Set:

```
VITE_API_URL=http://localhost:5000/api
```

---

# ğŸš€ **Deployment Guide**

### **Backend â†’ Render**

- Deploy GitHub repo
- Set Node version to 18
- Add all environment variables
- [Backend URL:](https://ai-news-chatbot-backend.onrender.com)
    
    ```
    https://ai-news-chatbot-backend.onrender.com
    ```
    

### **Frontend â†’ Vercel**

- Import GitHub repo
- Build command: `npm run build`
- Output folder: `dist`
- **Frontend URL:**
    
    ```
    https://ai-news-chatbot-frontend-57mnd7b5c-mdizharuls-projects.vercel.app/api
    ```
    

---

# ğŸ’¡ **Noteworthy Design Decisions**

### âœ” Batch embeddings (Jina)

Better performance than single embedding per article.

### âœ” Qdrant Vector DB

Persistent ANN search with metadata and high throughput.

### âœ” Redis TTL-based session storage

Efficient, scalable, self-cleaning.

### âœ” RAG architecture

Ensures factual, source-grounded answers.

### âœ” Clear modular backend

- `services.js` â†’ business logic
- `routes.js` â†’ routing
- `config.js` â†’ environment
- `redis` + `qdrant` + `jina` integrations

---

# ğŸ“ˆ **Possible Improvements**

### ğŸ”¹ Article chunking for even better RAG

### ğŸ”¹ Background cron job to refresh news hourly

### ğŸ”¹ Add WebSocket streaming from Gemini

### ğŸ”¹ Hybrid search (BM25 + Vector)

### ğŸ”¹ Add authentication (JWT)

### ğŸ”¹ Add rate limiting